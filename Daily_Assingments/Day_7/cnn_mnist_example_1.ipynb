{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5f5422fc",
      "metadata": {
        "id": "5f5422fc"
      },
      "source": [
        "# Digit Classification with a Convolutional Neural Network (CNN)\n",
        "This notebook demonstrates how to build and train a CNN using TensorFlow and Keras to classify images from the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the libraries"
      ],
      "metadata": {
        "id": "rPYi-qjJbQCo"
      },
      "id": "rPYi-qjJbQCo"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a6c8199b",
      "metadata": {
        "id": "a6c8199b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CNN](https://user-images.githubusercontent.com/34989887/206905433-34b42cbf-3ce3-4703-a575-d48f2cc95c09.png)\n",
        "\n",
        "## Load the data, reshape and normalize the images, and convert labels to one-hot format."
      ],
      "metadata": {
        "id": "oSwE8Qo8cODz"
      },
      "id": "oSwE8Qo8cODz"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a84fd9a",
      "metadata": {
        "id": "7a84fd9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2ba9d5-6bc2-46da-a67b-5787fc2e4f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Resize and Normalize the Data: essential for feeding image data into a convolutional neural network (CNN).\n",
        "#Reshapes the input data to have a shape compatible with CNNs. Each image is 28×28 pixels with 1 channel (grayscale).\n",
        "#Converts the pixel values to 32-bit floating-point numbers, which is standard for neural network input.\n",
        "#Normalizes pixel values from the range [0, 255] to [0, 1], which helps the model train more efficiently.\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# One-Hot Encode the Labels: Converts class labels (integers) into one-hot encoded vectors\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defines the architecture of the CNN model"
      ],
      "metadata": {
        "id": "Yq1qsuzZcZHa"
      },
      "id": "Yq1qsuzZcZHa"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d90229d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d90229d1",
        "outputId": "2695d652-e771-43be-f735-1fb6a1eed52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN Model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "#This is a full, step-by-step explanation of the previous code:\n",
        "#1st layer with 32 filters of size 3×3. Uses ReLU activation. Accepts input images of shape 28×28 pixels with 1 channel (grayscale).\n",
        "#Downsamples the feature maps by taking the maximum value in each 2×2 window. Reduces spatial dimensions\n",
        "#2nd convolutional layer with 64 filters of size 3×3. Further extracts features from the pooled output.\n",
        "#Another pooling layer to reduce the spatial size again.\n",
        "#Flatten: Converts the 2D feature maps into a 1D vector to feed into the dense layers.\n",
        "#Fully connected layer with 64 neurons and ReLU activation. Learns complex patterns from the extracted features.\n",
        "#Output layer with 10 neurons, one for each class (e.g., digits 0–9 in MNIST). Softmax activation outputs a probability distribution over the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepares and trains the CNN model on the data"
      ],
      "metadata": {
        "id": "x5FqUc-9cklL"
      },
      "id": "x5FqUc-9cklL"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e801783a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e801783a",
        "outputId": "db6c4a6e-095c-4a01-f168-403d7364f9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 57ms/step - accuracy: 0.8625 - loss: 0.4455 - val_accuracy: 0.9845 - val_loss: 0.0530\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 56ms/step - accuracy: 0.9813 - loss: 0.0588 - val_accuracy: 0.9872 - val_loss: 0.0414\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 54ms/step - accuracy: 0.9877 - loss: 0.0378 - val_accuracy: 0.9877 - val_loss: 0.0451\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.9903 - loss: 0.0306 - val_accuracy: 0.9898 - val_loss: 0.0409\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9902 - val_loss: 0.0348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7baef09404d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Compile and Train the Model\n",
        "#This step configures the model for training: Adam optimizer, categorical_crossentropy, tracks accuracy during training and validation\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Trains the CNN model using the training data:\n",
        "#epochs=5: The model will go through the entire training dataset 5 times.\n",
        "#batch_size=64: The training data is divided into batches of 64 samples. The model updates its weights after each batch.\n",
        "#validation_split=0.1: 10% of the training data is used for validation. This helps monitor the model’s performance on unseen data during training.\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model performance"
      ],
      "metadata": {
        "id": "-WkwSI9Sd6Be"
      },
      "id": "-WkwSI9Sd6Be"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6db7163",
      "metadata": {
        "id": "d6db7163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec307b80-1384-428c-8c3e-3a70cf890731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0420\n",
            "Precisión en el conjunto de prueba: 0.9889\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model on the Test Set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Precisión en el conjunto de prueba: {test_acc:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}